{"cells":[{"cell_type":"markdown","metadata":{},"source":["Goal: Add convolution, see what happens."]},{"cell_type":"code","execution_count":317,"metadata":{},"outputs":[],"source":["import torch"]},{"cell_type":"code","execution_count":318,"metadata":{},"outputs":[],"source":["import torchvision.datasets as datasets\n","from torchvision import transforms\n","\n","transform = transforms.Compose([\n","    transforms.ToTensor(),\n","])\n","\n","train_data = datasets.MNIST(root=\"./data\", train=True, download=True, transform=transform)\n","test_data = datasets.MNIST(root=\"./data\", train=False, download=True, transform=transform)"]},{"cell_type":"code","execution_count":319,"metadata":{},"outputs":[],"source":["from torch.utils.data import DataLoader\n","from torch.utils.data import random_split\n","\n","train_split = 0.8\n","train_size = int(train_split * len(train_data))\n","val_size = len(train_data) - train_size\n","\n","train_subset, val_subset = random_split(train_data, [train_size, val_size])\n","\n","train_loader = DataLoader(dataset=train_subset, batch_size=64, shuffle=True)\n","val_loader = DataLoader(dataset=val_subset, batch_size=64, shuffle=False)\n","test_loader = DataLoader(dataset=test_data, batch_size=64, shuffle=False)\n"]},{"cell_type":"code","execution_count":320,"metadata":{},"outputs":[],"source":["import torch.nn as nn\n","import torch.optim as optim\n","\n","class Skynet(nn.Module):\n","    def __init__(self, input_size, hidden_size, output_size):\n","        super().__init__()\n","        dropout_rate = 0.5\n","        self.conv = nn.Conv2d(in_channels=1, out_channels=16, kernel_size=3)\n","        self.relu1 = nn.ReLU()\n","        self.drop = nn.Dropout(p=dropout_rate)\n","        self.conv2 = nn.Conv2d(in_channels=16, out_channels=64, kernel_size=3, stride=2, padding=1)\n","        self.relu2 = nn.ReLU()\n","        self.drop0 = nn.Dropout(p=dropout_rate)\n","        self.conv3 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=2, padding=1)\n","        self.relu0 = nn.ReLU()\n","        self.flatten = nn.Flatten()\n","        self.drop2 = nn.Dropout(p=dropout_rate)\n","        # self.fc = nn.Linear((26 // 2) ** 2 * 32, 64)\n","        self.fc = nn.Linear((26 // 2 // 2 + 1) ** 2 * 64, 64)\n","        self.relu3 = nn.ReLU()\n","        self.drop3 = nn.Dropout(p=dropout_rate)\n","        self.fc2 = nn.Linear(64, 64)\n","        self.relu4 = nn.ReLU()\n","        self.drop4 = nn.Dropout(p=dropout_rate)\n","        self.output = nn.Linear(64, output_size)\n","\n","    def forward(self, x):\n","        # x = x.view(x.size(0), -1)\n","        x = self.conv(x)\n","        x = self.relu1(x)\n","        # x = self.drop(x)\n","        x = self.conv2(x)\n","        x = self.relu2(x)\n","        # x = self.drop0(x)\n","        x = self.conv3(x)\n","        x = self.relu0(x)\n","        x = self.flatten(x)\n","        x = self.drop2(x)\n","        x = self.fc(x)\n","        x = self.relu3(x)\n","        x = self.drop3(x)\n","        # x = self.fc2(x)\n","        # x = self.relu4(x)\n","        # x = self.drop4(x)\n","        x = self.output(x)\n","        return x"]},{"cell_type":"code","execution_count":321,"metadata":{},"outputs":[],"source":["input_size = 28 ** 2\n","hidden_size = 64\n","output_size = 10\n","\n","model = Skynet(input_size, hidden_size, output_size)\n"]},{"cell_type":"code","execution_count":322,"metadata":{},"outputs":[],"source":["loss_func = torch.nn.CrossEntropyLoss()"]},{"cell_type":"code","execution_count":323,"metadata":{},"outputs":[],"source":["optimizer = torch.optim.SGD(model.parameters(), lr=0.2)"]},{"cell_type":"code","execution_count":324,"metadata":{},"outputs":[],"source":["def train_one_epoch():\n","    model.train(True)\n","    batches = 0\n","    avg_loss = 0\n","    for step, (features, labels) in enumerate(train_loader):\n","        optimizer.zero_grad()\n","        preds = model(features)\n","        loss = loss_func(preds, labels)\n","        loss.backward()\n","        optimizer.step()\n","        \n","        avg_loss += loss\n","        batches = step\n","    \n","    avg_loss = avg_loss / batches\n","    print(f\"Average loss for training batches in this epoch: {avg_loss}\")\n","\n","    model.train(False)\n","    batches = 0\n","    avg_loss = 0\n","    for step, (features, labels) in enumerate(val_loader):\n","        preds = model(features)\n","        loss = loss_func(preds, labels)\n","        \n","        avg_loss += loss\n","        batches = step\n","\n","    avg_loss = avg_loss / batches\n","    print(f\"Average loss for validation batches in this epoch: {avg_loss}\")\n"]},{"cell_type":"code","execution_count":325,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Beginning epoch 0...\n"]},{"name":"stdout","output_type":"stream","text":["Average loss for training batches in this epoch: 0.5724272727966309\n","Average loss for validation batches in this epoch: 0.11559341847896576\n","\n","Beginning epoch 1...\n","Average loss for training batches in this epoch: 0.22905036807060242\n","Average loss for validation batches in this epoch: 0.08167652785778046\n","\n","Beginning epoch 2...\n","Average loss for training batches in this epoch: 0.17224152386188507\n","Average loss for validation batches in this epoch: 0.07707299292087555\n","\n","Beginning epoch 3...\n","Average loss for training batches in this epoch: 0.15115809440612793\n","Average loss for validation batches in this epoch: 0.05965511128306389\n","\n","Beginning epoch 4...\n","Average loss for training batches in this epoch: 0.132662832736969\n","Average loss for validation batches in this epoch: 0.05624872446060181\n","\n","Beginning epoch 5...\n","Average loss for training batches in this epoch: 0.121321901679039\n","Average loss for validation batches in this epoch: 0.04873475804924965\n","\n","Beginning epoch 6...\n","Average loss for training batches in this epoch: 0.11292809993028641\n","Average loss for validation batches in this epoch: 0.049157220870256424\n","\n","Beginning epoch 7...\n","Average loss for training batches in this epoch: 0.10650932043790817\n","Average loss for validation batches in this epoch: 0.0478067547082901\n","\n","Beginning epoch 8...\n","Average loss for training batches in this epoch: 0.10123621672391891\n","Average loss for validation batches in this epoch: 0.04487644135951996\n","\n","Beginning epoch 9...\n","Average loss for training batches in this epoch: 0.09374592453241348\n","Average loss for validation batches in this epoch: 0.04109736904501915\n","\n","Beginning epoch 10...\n","Average loss for training batches in this epoch: 0.08930464088916779\n","Average loss for validation batches in this epoch: 0.04809689521789551\n","\n","Beginning epoch 11...\n","Average loss for training batches in this epoch: 0.08317103981971741\n","Average loss for validation batches in this epoch: 0.041671112179756165\n","\n","Beginning epoch 12...\n","Average loss for training batches in this epoch: 0.08159667253494263\n","Average loss for validation batches in this epoch: 0.04301971197128296\n","\n","Beginning epoch 13...\n","Average loss for training batches in this epoch: 0.08245039731264114\n","Average loss for validation batches in this epoch: 0.039971280843019485\n","\n","Beginning epoch 14...\n","Average loss for training batches in this epoch: 0.07756098359823227\n","Average loss for validation batches in this epoch: 0.03964713588356972\n","\n"]}],"source":["model.train(True)\n","for i in range (0, 15):\n","    print(f\"Beginning epoch {i}...\")\n","    train_one_epoch()\n","    print(\"\")"]},{"cell_type":"code","execution_count":326,"metadata":{},"outputs":[],"source":["model.train(False)\n","preds = []\n","for features, labels in test_loader:\n","    with torch.no_grad():\n","        batch_preds = model(features)\n","        preds.extend(batch_preds.tolist())"]},{"cell_type":"code","execution_count":327,"metadata":{},"outputs":[],"source":["preds_tensor = torch.tensor(preds)\n","category_preds = torch.argmax(preds_tensor, dim=1)"]},{"cell_type":"code","execution_count":328,"metadata":{},"outputs":[],"source":["def check_accuracy(preds, actual):\n","    if len(actual) != len(preds):\n","        return -1\n","    return sum([int(actual[i] == preds[i]) for i in range(0, len(actual))]) / len(actual)"]},{"cell_type":"code","execution_count":329,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy: 0.9902\n"]}],"source":["print(f\"Accuracy: {check_accuracy(category_preds, test_data.targets)}\")"]},{"cell_type":"markdown","metadata":{},"source":["0.983\n","\n","0.9842\n","\n","0.9846\n","\n","0.9865\n","\n","0.9888\n","\n","0.9902"]},{"cell_type":"markdown","metadata":{},"source":["Sick, about 97.5% accuracy now! Big improvement from 85% in the last notebook. Next step: implement recurrency."]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.2"},"orig_nbformat":4},"nbformat":4,"nbformat_minor":2}
